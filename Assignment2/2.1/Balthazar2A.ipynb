{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This notebook implements and plots/animate a Diffusion Limited Aggregation Model\n",
    "\n",
    "Over a 2-D $n\\times n$ grid with diffusion simulated (by solving Laplace Equation with Successive over Relaxation method) from top ($c=1$) to bottom ($c=0$), we introduce an evergrowing 'sinkhole' (concentration is always null or does not interact with concentration outside the object) to our grid. This sinkhole grows by randomly, one-by-one, adding neighbouring cells to its body. The probability for a neighbour to become part of the sinkhole depends on their concentration (after SOR is solved at precision $10^{-5}$) and a parameter $\\eta$ which can provide more or less weight to neighbours and their concentration.  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from matplotlib import animation\n",
    "from IPython.display import HTML\n",
    "from numba import njit"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "@njit\n",
    "def update_contour(candidate_loc, contour, domain):\n",
    "    '''\n",
    "    This model of DLA relies on two (n x n) matrices:\n",
    "    domain : is where we solve the diffusion equation (through laPlace; SOR)\n",
    "    contour : is where the cluster (1s in the contour matrix) and the neighbouring candidates (2s) are tracked and updated\n",
    "    \n",
    "    Given a chosen candidate to aggregate, this function updates contour and thus the cluster accordingly.\n",
    "    '''\n",
    "    # initialize\n",
    "    n = len(contour)\n",
    "    x = candidate_loc[0]\n",
    "    y = candidate_loc[1]\n",
    "    domain[x, y] = 0\n",
    "    contour[x, y] = 1\n",
    "\n",
    "    # we now create a list of neighbours which we will reduce to include only the ones which should be part of the new contour\n",
    "    neighbours = []\n",
    "    \n",
    "    # I exempt the boundaries of the grid from being in the cluster for stability \n",
    "    if x > 0:\n",
    "        neighbours.append([x-1, y])\n",
    "    if y > 0:\n",
    "        neighbours.append([x, y-1])\n",
    "    if x < n-1:\n",
    "        neighbours.append([x+1, y])\n",
    "    if y < n-1:\n",
    "        neighbours.append([x, y+1])\n",
    "    # if the neighbours of our aggregated candidated are not in the cluster the are tracked (=2)\n",
    "    for neigh in neighbours: \n",
    "        if contour[neigh[0], neigh[1]] != 1 and neigh[0] in range(1, n-1) and neigh[1] in range(1, n-1):\n",
    "            contour[neigh[0], neigh[1]] = 2\n",
    "    # I pull the updated list of neighbouring candidates\n",
    "    candidates = [[i, j] for i in range(0,n) for j in range(0,n) if contour[i, j] == 2]\n",
    "    return contour, candidates\n",
    "\n",
    "def aggregate_candidate(candidates, domain, eta):\n",
    "    '''\n",
    "    Given the list \"candidates\" of coordinates of the neighbours of our cluster,\n",
    "    this function computes the probability of candidates to be chosen (p = c_ij**eta/sum(c_ij**eta))\n",
    "    and chooses one randomly, weighing each options probability p\n",
    "    '''\n",
    "    # create a list parallel to 'candidates' which includes each candidate's probability respectively\n",
    "    cand_eta = [(np.abs(domain[i, j]))**eta for [i, j] in candidates]\n",
    "    prob_cand = [c/np.sum(cand_eta) for c in cand_eta]\n",
    "    # I choose and 'return' a candidate randomly, based on their and other's probability\n",
    "    return candidates[np.random.choice(len(candidates), p = prob_cand)]\n",
    "\n",
    "@njit\n",
    "def sor_iteration(matrix, contour, w):\n",
    "    '''\n",
    "    This is one iteration of Successive over Relaxation method for solving laplace equation \n",
    "    with updated rules for elements in our cluster/sinkhole (when contour[i,j] == 1)\n",
    "    '''\n",
    "    n = len(matrix)\n",
    "    next_matrix = np.copy(matrix)\n",
    "        \n",
    "    for j in range (1, n-1):\n",
    "        # rule out if part of cluster/sinkhole\n",
    "        if contour[j,0] == 1:\n",
    "            next_matrix[j, 0] = 0\n",
    "        else:\n",
    "            # west boundary case where x = 0:\n",
    "            next_matrix[j,0] = w/4 * (matrix[j,1] + matrix[j,-2] + matrix[j+1,0] + next_matrix[j-1,0]) + (1 - w) * matrix[j, 0]\n",
    "\n",
    "        # non-boundary case \n",
    "        for i in range (1, n-1):\n",
    "            # rule out if part of cluster/sinkhole\n",
    "            if contour[j,i] == 1:\n",
    "                next_matrix[j, i] = 0\n",
    "            else:\n",
    "                next_matrix[j,i] = w/4 * (matrix[j,i+1] + next_matrix[j,i-1] + matrix[j+1,i] + next_matrix[j-1,i]) + (1 - w) * matrix[j, i]\n",
    "\n",
    "        # rule out if part of cluster/sinkhole\n",
    "        if contour[j,-1] == 1:\n",
    "            next_matrix[j, -1] = 0\n",
    "        else:\n",
    "            # east boundary case where x = n:\n",
    "            next_matrix[j,-1] = w/4 * (matrix[j,1] + matrix[j,-2] + matrix[j+1,-1] + next_matrix[j-1,-1]) + (1 - w) * matrix[j, -1]\n",
    "\n",
    "    return next_matrix\n",
    "\n",
    "@njit\n",
    "def sor(domain, contour, w, eps = 1e-5):\n",
    "    '''\n",
    "    this runs the above SOR iteration function until stability with precision eps = 1e-5\n",
    "    '''\n",
    "    # initialize our counter iter and set an initial value of convergence\n",
    "    conv = 1\n",
    "    iter = 0 # we track this for comparing omega values (which won't be done in this notebook)\n",
    "\n",
    "    # run sor_iteration until it converges with precision 1e-5\n",
    "    while conv > eps:\n",
    "        next_domain = sor_iteration(domain, contour, w)\n",
    "        diff = np.abs(next_domain - domain) \n",
    "        # absolute value because SOR can be unstable and produce negative values which breaks our aggregate function\n",
    "        # doing this introduce an error no greater than the one due to SOR's unstability\n",
    "        conv = np.max(diff)\n",
    "        domain = next_domain\n",
    "        iter += 1\n",
    "    return next_domain, iter\n",
    "\n",
    "def next_step(domain, contour, candidates, eta, w):\n",
    "    '''\n",
    "    This updates our domain with our evergrowing cluster (tracked in contour), I used this for the animation only\n",
    "    '''\n",
    "    # pick a 'winning' neighbouring candidate\n",
    "    cand = aggregate_candidate(candidates, domain, eta)\n",
    "    # update the contour accordingly\n",
    "    contour, candidates = update_contour(cand, contour, domain)\n",
    "    # solve the diffusion equation again with new cluster\n",
    "    domain, _ = sor(domain, contour, w)\n",
    "    return domain, contour, candidates"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The following kernel produces a $N$ size cluster with a given $\\eta$, solved by SOR with relaxation factor $\\omega$ over a grid of size $n\\times n$. It also plots the results once all aggregated candidates were added to the cluster."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "n = 100 # grid length (once squared)\n",
    "eta = 1.5 # shape parameter\n",
    "w = 1.7 # relaxation factor\n",
    "N = 400 #size of constructed cluster  \n",
    "\n",
    "# Initialize domain and contour\n",
    "domain = np.zeros((n, n))\n",
    "domain[0, :] = 1\n",
    "contour = np.zeros((n, n))\n",
    "# initialize a 1x1 cluster at the bottom/middle of the grid\n",
    "contour, candidates = update_contour([n-2, n//2], contour, domain)\n",
    "domain, iter = sor(domain, contour, w)\n",
    "\n",
    "for _ in range(N):\n",
    "    # pick a 'winning' neighbouring candidate\n",
    "    cand = aggregate_candidate(candidates, domain, eta)\n",
    "    # update the contour accordingly\n",
    "    contour, candidates = update_contour(cand, contour, domain)\n",
    "    # solve the diffusion equation again with new cluster\n",
    "    domain, _ = sor(domain, contour, w)\n",
    "\n",
    "\n",
    "# I change the resulting domain a little so the color map shows more contrast, thus we see the cluster better\n",
    "color_domain = np.copy(domain)\n",
    "for x in range(0, n):\n",
    "    for y in range(0, n):\n",
    "        if contour[x, y] == 1:\n",
    "            color_domain[x, y] = -1\n",
    "\n",
    "# plot the resulting grid and cluster\n",
    "im = plt.imshow(color_domain, cmap='hot_r')\n",
    "plt.xlabel(f\"x ({n})\")\n",
    "plt.ylabel(f\"y ({n})\")\n",
    "plt.title(fr\"Diffusion Limited Aggregation with $\\omega=${w} and $\\eta=${eta}, cluster of size {N}\")\n",
    "plt.xlim(1, n-1)\n",
    "plt.ylim(n-1, 1)\n",
    "#plt.savefig(\"dla_set2_2a.png\", dpi = 300)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The following kernel animates the iterated growth of a cluster given apposite parameters. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "n = 100 # grid length (once squared)\n",
    "eta = 1 # shape parameter\n",
    "w = 1.7\n",
    "N = 400\n",
    "\n",
    "# Initialize domain and contour\n",
    "domain = np.zeros((n, n))\n",
    "domain[0, :] = 1\n",
    "contour = np.zeros((n, n))\n",
    "contour, candidates = update_contour([n-2, n//2], contour, domain)\n",
    "domain, iter = sor(domain, contour, w)\n",
    "\n",
    "fig, ax = plt.subplots()\n",
    "im = ax.imshow(color_domain, cmap='hot_r', animated=True)\n",
    "\n",
    "ax.set_xlabel(f\"x ({n})\")\n",
    "ax.set_ylabel(f\"y ({n})\")\n",
    "ax.set_title(fr\"Diffusion Limited Aggregation with $\\omega=${w} and $\\eta=${eta}\")\n",
    "\n",
    "def update(frame):\n",
    "    global domain, contour, candidates\n",
    "    domain, contour, candidates = next_step(domain, contour, candidates, eta, w)\n",
    "    color_domain = np.copy(domain)\n",
    "    for x in range(0, n):\n",
    "        for y in range(0, n):\n",
    "            if contour[x, y] == 1:\n",
    "                color_domain[x, y] = -10\n",
    "    im.set_array(color_domain)\n",
    "    return [im]\n",
    "\n",
    "\n",
    "ani = animation.FuncAnimation(fig, update, frames=N, interval=10, blit=False)\n",
    "\n",
    "HTML(ani.to_jshtml())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For the rest of the notebook, I run the same model while trying to improve on the time required to solve the diffusion equation.\n",
    "The idea is to use a multigrid: the smaller (with step size 1/n) is used just like we did previously. A bigger grid (step size a/n for a>1>n) is used to solve the diffusion equation **above** the cluster.\n",
    "\n",
    "We need to track the height of the cluster\n",
    "and update sor_iteration() function "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "@njit\n",
    "def height_of_contour(contour):\n",
    "    '''\n",
    "    I measure and return the distance between the top of the grid and the top of the cluster\n",
    "    '''\n",
    "    height = -1\n",
    "    for i in range(len(contour)):\n",
    "        if 1 not in contour[i,:]:\n",
    "            height += 1\n",
    "        else:\n",
    "            break\n",
    "    return height\n",
    "\n",
    "def improved_sor_iteration(domain, contour, w, new_step_size):\n",
    "    '''\n",
    "    This one is a little bulky, probably not optimal. \n",
    "    In this function, I create a coarser grid with a bigger step size.\n",
    "    I first solve diffusion with sor for the coarse grid before it hits the object \n",
    "    (so only for the portion of the grid above the heighest point of the cluster)\n",
    "    I then spread this solution to the finer grid, \n",
    "    where every fine step takes the value of whichever coarse step they are in.\n",
    "    '''\n",
    "    height = height_of_contour(contour)\n",
    "    \n",
    "    # We rule out a new step size too large\n",
    "    if new_step_size > height:\n",
    "        return f'The given step size is too big'\n",
    "    \n",
    "    # set up dimensions of new/coarser grid\n",
    "    new_grid_size = height // new_step_size\n",
    "    n = len(domain[0])\n",
    "    new_grid = np.zeros((new_grid_size, n // new_step_size))\n",
    "    \n",
    "    init = [] #this has the unique task of being a 1. list above the coarse grid to allow proper solving\n",
    "    fin = [] #same with 0. under the coarse grid\n",
    "    \n",
    "    # let us create the new grid from average of corresponding finer grid \n",
    "    for j in range(n // new_step_size):\n",
    "        init.append(1.) \n",
    "        fin.append(0.)\n",
    "        \n",
    "        for i in range(1, new_grid_size):\n",
    "            sub_grid = [domain[h, k] for h in range(i * new_step_size, (i + 1) * new_step_size) \n",
    "                                       for k in range(j * new_step_size, (j + 1) * new_step_size)]\n",
    "            new_grid[i, j] = np.mean(sub_grid)\n",
    "    \n",
    "    # Prepare new grid by inserting boundary conditions\n",
    "    new_grid_prep = np.copy(new_grid)\n",
    "    new_grid_prep = np.insert(new_grid_prep, 0, init, axis=0)\n",
    "    new_grid_prep = np.append(new_grid_prep, [fin], axis=0)\n",
    "    \n",
    "    # Solve the new coarse grid\n",
    "    new_contour = np.zeros_like(new_grid_prep)\n",
    "    new_grid_solved, new_iter = sor(new_grid_prep, new_contour, w)\n",
    "    new_grid_solved = new_grid_solved[1:-1]  # Remove the added boundary rows (init and fin)\n",
    "    \n",
    "    # Map the solved coarse grid back to the fine grid\n",
    "    for j in range(n // new_step_size):\n",
    "        for i in range(1, new_grid_size):\n",
    "            domain[i * new_step_size:(i + 1) * new_step_size, j * new_step_size:(j + 1) * new_step_size] = new_grid_solved[i, j]\n",
    "    \n",
    "    return domain, new_iter\n",
    "\n",
    "\n",
    "def improved_sor(domain, contour, w, new_step_size):\n",
    "    '''\n",
    "    This is a certain sequence for multigrid solving\n",
    "    I would have tested more but this one served to improve on regular sor.\n",
    "    1. Solve the coarse grid above object\n",
    "    2. Solve the finer grid for the whole domain\n",
    "    end\n",
    "    '''\n",
    "    #Solve coarser grid\n",
    "    domain, new_iter = improved_sor_iteration(domain, contour, w, new_step_size)\n",
    "    \n",
    "    #solve finer grid\n",
    "    domain, iter = sor(domain, contour, w)\n",
    "    \n",
    "    return domain, iter + new_iter\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def improved_sor_iteration_2(domain, contour, w, new_step_size):\n",
    "    '''\n",
    "    this is the last version of SOR with multi grid solved over the whole domain (not only above the cluster)\n",
    "    On the coarser grid, any coarse step which contains any finer step part of the cluster, is consider part of the cluster when solving coarse grid \n",
    "    '''\n",
    "    n = len(domain[0])\n",
    "    \n",
    "    # We rule out a new step size too large\n",
    "    # set up dimensions of new/coarser grid\n",
    "    new_grid_size = n // new_step_size\n",
    "    new_grid = np.zeros((new_grid_size, n // new_step_size))\n",
    "    new_contour = np.zeros((new_grid_size, n // new_step_size))\n",
    "    \n",
    "    init = [] #this has the unique task of being a 1. list above the coarse grid to allow proper solving\n",
    "    fin = [] #same with 0. under the coarse grid\n",
    "    \n",
    "    # let us create the new grid from average of corresponding finer grid \n",
    "    for j in range(new_grid_size):\n",
    "        init.append(1.) \n",
    "        fin.append(0.)\n",
    "        \n",
    "        for i in range(1, new_grid_size-1):\n",
    "            sub_grid = [domain[h, k] for h in range(i * new_step_size, (i + 1) * new_step_size) \n",
    "                                       for k in range(j * new_step_size, (j + 1) * new_step_size)]\n",
    "            contour_sub_grid = [contour[h, k] for h in range(i * new_step_size, (i + 1) * new_step_size) \n",
    "                                       for k in range(j * new_step_size, (j + 1) * new_step_size)]\n",
    "            if np.any(contour_sub_grid == 1):\n",
    "                new_contour[i, j] = 1\n",
    "                new_grid[i, j] = 0\n",
    "            else:\n",
    "                new_grid[i, j] = np.mean(sub_grid)\n",
    "    \n",
    "    # Prepare new grid by inserting boundary conditions\n",
    "    new_grid_prep = np.copy(new_grid)\n",
    "    new_grid_prep = np.insert(new_grid_prep, 0, init, axis=0)\n",
    "    new_grid_prep = np.append(new_grid_prep, [fin], axis=0)\n",
    "    \n",
    "    # Solve the new coarse grid\n",
    "    new_grid_solved, new_iter = sor(new_grid_prep, new_contour, w)\n",
    "    new_grid_solved = new_grid_solved[1:-1]  # Remove the added boundary rows (init and fin)\n",
    "    \n",
    "    # Map the solved coarse grid back to the fine grid\n",
    "    for j in range(new_grid_size):\n",
    "        for i in range(1, new_grid_size-1):\n",
    "            domain[i * new_step_size:(i + 1) * new_step_size, j * new_step_size:(j + 1) * new_step_size] = new_grid_solved[i, j]\n",
    "    \n",
    "    return domain, new_iter\n",
    "\n",
    "\n",
    "def improved_sor_2(domain, contour, w, new_step_size):\n",
    "    '''\n",
    "    This is a certain sequence for multigrid solving\n",
    "    1. Solve the coarse grid\n",
    "    2. Solve the finer grid for the whole domain\n",
    "    end\n",
    "    '''\n",
    "    #Solve coarser grid\n",
    "    domain, new_iter = improved_sor_iteration_2(domain, contour, w, new_step_size)\n",
    "    \n",
    "    #solve finer grid\n",
    "    domain, iter = sor(domain, contour, w)\n",
    "    \n",
    "    return domain, iter + new_iter\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "n = 200 # grid length (once squared)\n",
    "eta = 1.5 # shape parameter\n",
    "w = 1.7 # relaxation factor\n",
    "N = 400 #size of constructed cluster  \n",
    "\n",
    "# Initialize domain and contour\n",
    "domain = np.zeros((n, n))\n",
    "domain[0, :] = 1\n",
    "contour = np.zeros((n, n))\n",
    "# initialize a 1x1 cluster at the bottom/middle of the grid\n",
    "contour, candidates = update_contour([n-2, n//2], contour, domain)\n",
    "domain, iter = sor(domain, contour, w)\n",
    "\n",
    "for _ in range(N):\n",
    "    # pick a 'winning' neighbouring candidate\n",
    "    cand = aggregate_candidate(candidates, domain, eta)\n",
    "    # update the contour accordingly\n",
    "    contour, candidates = update_contour(cand, contour, domain)\n",
    "    # solve the diffusion equation again with new cluster\n",
    "    domain, _ = sor(domain, contour, w)\n",
    "\n",
    "\n",
    "# I change the resulting domain a little so the color map shows more contrast, thus we see the cluster better\n",
    "color_domain = np.copy(domain)\n",
    "for x in range(0, n):\n",
    "    for y in range(0, n):\n",
    "        if contour[x, y] == 1:\n",
    "            color_domain[x, y] = -1\n",
    "\n",
    "# plot the resulting grid and cluster\n",
    "im = plt.imshow(color_domain, cmap='hot_r')\n",
    "plt.xlabel(f\"x ({n})\")\n",
    "plt.ylabel(f\"y ({n})\")\n",
    "plt.title(fr\"Diffusion Limited Aggregation with $\\omega=${w} and $\\eta=${eta}, cluster of size {N}\")\n",
    "plt.xlim(1, n-1)\n",
    "plt.ylim(n-1, 1)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Test for sor solution to diffusion\n",
    "domain = np.zeros((n, n))\n",
    "domain[0, :] = 1\n",
    "domain, iter = sor(domain, contour, w)\n",
    "print(iter, domain)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Test for improved sor solution to diffusion\n",
    "domain = np.zeros((n, n))\n",
    "domain[0, :] = 1\n",
    "domain, iter = improved_sor(domain, contour, w, new_step_size=10)\n",
    "print(iter, domain)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Test for second improved sor solution to diffusion\n",
    "domain = np.zeros((n, n))\n",
    "domain[0, :] = 1\n",
    "domain, iter = improved_sor_2(domain, contour, w, new_step_size=10)\n",
    "print(iter, domain)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "These three tests may not show any big improvements\n",
    "In fact, for some values of 'new_step_size', the multigrid process requires more iterations. But I ran these tests for $n=500$, with some $400$ sized cluster:\n",
    "- SOR required $16933$ iterations\n",
    "- Improved_SOR required $14202$ iterations(new_step_size $=10$)\n",
    "- Improved_SOR_2 required $1881$ iterations(new_step_size $=10$)\n",
    "\n",
    "You can test this (5 min) by changing $n$ to $500$ in the kernel above the 3 tests and rerunning them.\n",
    "I didn't test this too much but the multigrids definitely improve on sor solution."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
